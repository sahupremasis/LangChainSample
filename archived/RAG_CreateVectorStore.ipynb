{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3426a0",
   "metadata": {},
   "source": [
    "# Indexing: Creating a Chroma Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee55348c-742a-4923-835d-ae8d3ba2ad8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:13.047164Z",
     "start_time": "2026-01-14T15:52:13.043735Z"
    }
   },
   "source": [
    "# Run the line of code below to check the version of langchain in the current environment.\n",
    "# Substitute \"langchain\" with any other package name to check their version."
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1132f9d9-294d-43e5-bbe7-22c7d36dc3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:14.435708Z",
     "start_time": "2026-01-14T15:52:13.056094Z"
    }
   },
   "source": [
    "pip show langchain"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.2.3\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Premasis\\Development\\Pycharm\\LangChainSample\\.venv\\Lib\\site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "981b833a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:14.462272Z",
     "start_time": "2026-01-14T15:52:14.456171Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "b6e014fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:14.491835Z",
     "start_time": "2026-01-14T15:52:14.473800Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "fe47944c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:14.833220Z",
     "start_time": "2026-01-14T15:52:14.497701Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Task (clarified): Load a DOCX file, split its text first by Markdown-like headers and then into\n",
    "smaller character-based chunks, normalize whitespace in each chunk, and prepare an OpenAI\n",
    "embedding model to embed those chunks later for vector storage / retrieval.\n",
    "\"\"\"\n",
    "\n",
    "# 1) Load the DOCX into LangChain Document objects\n",
    "# loader_docx = Docx2txtLoader(\"Data_Science_Readme.docx\")\n",
    "# pages = loader_docx.load()\n",
    "\n",
    "loader_txt = TextLoader(\"IntroductionToDataScience.txt\", encoding=\"utf-8\")\n",
    "pages = loader_txt.load()\n",
    "# 2) Split the first document's text by Markdown-style headers (e.g., \"#\", \"##\")\n",
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[(\"#\", \"Course Title\"), (\"##\", \"Lecture Title\")]\n",
    ")\n",
    "pages_md_split = md_splitter.split_text(pages[0].page_content)\n",
    "\n",
    "# 3) Normalize whitespace inside each split document (collapse newlines/tabs/multiple spaces)\n",
    "for i in range(len(pages_md_split)):\n",
    "    pages_md_split[i].page_content = \" \".join(pages_md_split[i].page_content.split())\n",
    "\n",
    "# 4) Further split header-based documents into smaller overlapping chunks using \".\" as a separator\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\".\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "pages_char_split = char_splitter.split_documents(pages_md_split)\n",
    "\n",
    "# 5) Create an embeddings client/model (used later to embed the chunks)\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "83e55c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:14.851577Z",
     "start_time": "2026-01-14T15:52:14.845070Z"
    }
   },
   "source": [
    "len(pages_char_split)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:17.043262Z",
     "start_time": "2026-01-14T15:52:14.858944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Task: Explain what this cell does by adding an inline, human-readable description,\n",
    "while keeping the original behavior (building and persisting the Chroma vectorstore).\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    \"Creating a Chroma vectorstore from `pages_char_split` by computing embeddings with `embedding`, \"\n",
    "    \"then persisting the resulting index/database to './local-database' for later reuse.\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=pages_char_split,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"./local-database\",\n",
    ")\n"
   ],
   "id": "b9694d275ccb1f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Chroma vectorstore from `pages_char_split` by computing embeddings with `embedding`, then persisting the resulting index/database to './local-database' for later reuse.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:17.114809Z",
     "start_time": "2026-01-14T15:52:17.051304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorstore_from_directory = Chroma(persist_directory = \"./local-database\",\n",
    "                                    embedding_function = embedding)"
   ],
   "id": "bd429c41b459019c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T15:52:17.122832Z",
     "start_time": "2026-01-14T15:52:17.119321Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4db235f33893619d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
